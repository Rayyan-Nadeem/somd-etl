{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6b2ec7",
   "metadata": {},
   "source": [
    "# ETL Process for CSV Files\n",
    "This notebook demonstrates an ETL process for the CSV files in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "082f2a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba46228",
   "metadata": {},
   "source": [
    "## Load CSV Files\n",
    "Load the CSV files from the directory into pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbc1dc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AthleteId', 'Parent2Email', 'GrpHome', 'Active', 'LastName', 'FirstName', 'Sex', 'DateOfBirth', 'SSN', 'ParentName', 'ParentAddress', 'ParentCity', 'ParentState', 'ParentZIP', 'ParentPhone', 'ParentCell', 'ParentEMail', 'Parent2Name', 'Parent2Address', 'Parent2City', 'Parent2State', 'Parent2Zip', 'Parent2Phone', 'Parent2Cell', 'HomePhone', 'EmergencyNbr', 'AthleteAddress', 'AthleteCity', 'AthleteState', 'AthleteZip', 'AthleteEMail', 'CounselorName', 'CounselorEMail', 'CounselorPhone', 'AgencyName', 'DrNamePhone', 'Downs', 'AaAx', 'NoXray', 'Photo', 'Na/Rl', 'Allgeries', 'Tetnus', 'Medication', 'Comments', 'MedicalDeadline', 'PhotoRelease', 'AlternatePhone', 'EntryDate', 'TorchRunner', 'AwardsComments', 'Deactivation_Dt']\n",
      "   AthleteId            Parent2Email GrpHome  Active              LastName  \\\n",
      "0       1445     carterg22@gmail.com      NO    True                   NaN   \n",
      "1       1320                     NaN      NO   False                   NaN   \n",
      "2       1477                     NaN      NO    True                   NaN   \n",
      "3       1034                     NaN      NO    True            Abdelhalim   \n",
      "4         18  khalil@shuraforall.org      No    True  Abdul-Rahman (Flynn)   \n",
      "\n",
      "  FirstName  Sex DateOfBirth  SSN       ParentName  ...     Tetnus  \\\n",
      "0       NaN    F   30-Jan-14  NaN      Tori Carter  ...        NaN   \n",
      "1       NaN  NaN         NaN  NaN              NaN  ...        NaN   \n",
      "2       NaN    M   13-Aug-12  NaN  Masooma Hasnain  ...        NaN   \n",
      "3      Mona    F   25-Sep-01  NaN   Fatima H Kahil  ...        NaN   \n",
      "4   Ahleyah    F   20-Nov-83  NaN      Joyce Flynn  ...  15-Aug-88   \n",
      "\n",
      "                                          Medication  \\\n",
      "0  Zoloft, 75mg, qd\\nClanidine, 2mg, qhs\\nExlax, ...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3  insulin aspert, 3xday\\ndexem G7, every 10days\\...   \n",
      "4  clonazapam, 0.5mg, 2xday\\nLevothyroxine, 50mcg...   \n",
      "\n",
      "                                            Comments MedicalDeadline  \\\n",
      "0                                             Autism       05-Mar-27   \n",
      "1                                                NaN             NaN   \n",
      "2                                             Autism       26-Jun-27   \n",
      "3                                                NaN       14-Aug-27   \n",
      "4  Glasses, Repaired CHD as infant, reactive airw...       26-Oct-26   \n",
      "\n",
      "  PhotoRelease AlternatePhone  EntryDate TorchRunner AwardsComments  \\\n",
      "0        False            NaN  3/18/2024       False            NaN   \n",
      "1        False            NaN  2/17/2020       False            NaN   \n",
      "2        False            NaN  8/10/2024       False            NaN   \n",
      "3        False            NaN  3/10/2017       False            NaN   \n",
      "4        False            NaN  4/25/1995       False            NaN   \n",
      "\n",
      "  Deactivation_Dt  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n",
      "\n",
      "[5 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load CSV files\n",
    "athletes_df = pd.read_csv('athletes.csv', encoding='latin1')\n",
    "\n",
    "# Display the first rows of the DataFrame\n",
    "print(athletes_df.columns.tolist())\n",
    "print(athletes_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8badc973",
   "metadata": {},
   "source": [
    "## Transform Data\n",
    "Perform necessary transformations on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "325cad03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AthleteId            Parent2Email GrpHome  Active  Sex DateOfBirth  SSN  \\\n",
      "0       1445     carterg22@gmail.com      NO    True    F   30-Jan-14  NaN   \n",
      "1       1320                     NaN      NO   False  NaN         NaN  NaN   \n",
      "2       1477                     NaN      NO    True    M   13-Aug-12  NaN   \n",
      "3       1034                     NaN      NO    True    F   25-Sep-01  NaN   \n",
      "4         18  khalil@shuraforall.org      No    True    F   20-Nov-83  NaN   \n",
      "\n",
      "        ParentName             ParentAddress ParentCity  ...  \\\n",
      "0      Tori Carter                       NaN        NaN  ...   \n",
      "1              NaN                       NaN        NaN  ...   \n",
      "2  Masooma Hasnain                       NaN        NaN  ...   \n",
      "3   Fatima H Kahil                       NaN        NaN  ...   \n",
      "4      Joyce Flynn  7725 Hornbeam Drive #243   Elkridge  ...   \n",
      "\n",
      "                                          Medication  \\\n",
      "0  Zoloft, 75mg, qd\\nClanidine, 2mg, qhs\\nExlax, ...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3  insulin aspert, 3xday\\ndexem G7, every 10days\\...   \n",
      "4  clonazapam, 0.5mg, 2xday\\nLevothyroxine, 50mcg...   \n",
      "\n",
      "                                            Comments MedicalDeadline  \\\n",
      "0                                             Autism       05-Mar-27   \n",
      "1                                                NaN             NaN   \n",
      "2                                             Autism       26-Jun-27   \n",
      "3                                                NaN       14-Aug-27   \n",
      "4  Glasses, Repaired CHD as infant, reactive airw...       26-Oct-26   \n",
      "\n",
      "  PhotoRelease AlternatePhone  EntryDate TorchRunner AwardsComments  \\\n",
      "0        False            NaN  3/18/2024       False            NaN   \n",
      "1        False            NaN  2/17/2020       False            NaN   \n",
      "2        False            NaN  8/10/2024       False            NaN   \n",
      "3        False            NaN  3/10/2017       False            NaN   \n",
      "4        False            NaN  4/25/1995       False            NaN   \n",
      "\n",
      "  Deactivation_Dt                          name  \n",
      "0             NaN                           NaN  \n",
      "1             NaN                           NaN  \n",
      "2             NaN                           NaN  \n",
      "3             NaN               Mona Abdelhalim  \n",
      "4             NaN  Ahleyah Abdul-Rahman (Flynn)  \n",
      "\n",
      "[5 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "# Standardize column names to match the CSV header\n",
    "\n",
    "# Combine FirstName and LastName if columns exist\n",
    "if 'FirstName' in athletes_df.columns and 'LastName' in athletes_df.columns:\n",
    "    athletes_df['name'] = athletes_df['FirstName'] + ' ' + athletes_df['LastName']\n",
    "    # Drop the FirstName and LastName columns\n",
    "    athletes_df.drop(['FirstName', 'LastName'], axis=1, inplace=True)\n",
    "else:\n",
    "    print('FirstName or LastName column is missing.')\n",
    "\n",
    "# Display the first rows of the DataFrame\n",
    "print(athletes_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf89f10",
   "metadata": {},
   "source": [
    "## Export Parents/Guardians Data\n",
    "Create a separate CSV file for parents/guardians, linking them to athletes using AthleteId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c67e11fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped parent data saved to athlete_parents.csv\n"
     ]
    }
   ],
   "source": [
    "# Define a function to normalize phone numbers\n",
    "def normalize_phone(phone):\n",
    "    if pd.notna(phone):\n",
    "        # Remove non-numeric characters\n",
    "        return re.sub(r'\\D', '', phone)\n",
    "    return None\n",
    "\n",
    "# Define a function to map parent/guardian data based on a prefix\n",
    "def map_parent(row, prefix):\n",
    "    if prefix == \"Parent2\":\n",
    "        email_key = \"Parent2Email\"  # fix: use correct key for Parent2\n",
    "        zip_col = f\"{prefix}Zip\"\n",
    "    else:\n",
    "        email_key = f\"{prefix}EMail\"\n",
    "        zip_col = f\"{prefix}ZIP\"\n",
    "    return {\n",
    "        \"id\": row[\"AthleteId\"],\n",
    "        \"name\": row[f\"{prefix}Name\"],\n",
    "        \"primaryPhone\": normalize_phone(row[f\"{prefix}Phone\"]),\n",
    "        \"secondaryPhone\": normalize_phone(row.get(f\"{prefix}Cell\")),\n",
    "        \"email\": row[email_key].lower() if pd.notna(row[email_key]) else None,\n",
    "        \"street\": row.get(f\"{prefix}Address\"),\n",
    "        \"city\": row.get(f\"{prefix}City\"),\n",
    "        \"state\": row.get(f\"{prefix}State\"),\n",
    "        \"zip\": row.get(zip_col)\n",
    "    }\n",
    "\n",
    "# Initialize an empty list to store mapped parent data\n",
    "mapped_parents = []\n",
    "# Iterate over each row in the athletes_df DataFrame\n",
    "for _, row in athletes_df.iterrows():\n",
    "    # Map Parent 1 if required fields are present\n",
    "    if pd.notna(row[\"ParentName\"]) and pd.notna(row[\"ParentPhone\"]):\n",
    "        mapped_parents.append(map_parent(row, \"Parent\"))\n",
    "    # Map Parent 2 if required fields are present\n",
    "    if pd.notna(row[\"Parent2Name\"]) and pd.notna(row[\"Parent2Phone\"]):\n",
    "        mapped_parents.append(map_parent(row, \"Parent2\"))\n",
    "\n",
    "# Convert the mapped data to a DataFrame and export to CSV\n",
    "mapped_parents_df = pd.DataFrame(mapped_parents)\n",
    "# Removed sort_values to maintain original AthleteId order\n",
    "mapped_parents_df.to_csv('athlete_parents.csv', index=False)\n",
    "print('Mapped parent data saved to athlete_parents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f912bd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent-related columns removed.\n"
     ]
    }
   ],
   "source": [
    "# Strip parent-related columns from athletes_df if they exist\n",
    "columns_to_drop = ['ParentName', 'ParentPhone', 'ParentCell', 'ParentEMail', 'ParentAddress', 'ParentCity', 'ParentState', 'ParentZIP',\n",
    "                  'Parent2Name', 'Parent2Phone', 'Parent2Cell', 'Parent2Email', 'Parent2Address', 'Parent2City', 'Parent2State', 'Parent2Zip']\n",
    "# Adjust drop to use case-insensitive matching for parent-related columns\n",
    "cols_lower = {col.lower(): col for col in athletes_df.columns}\n",
    "existing_columns = [cols_lower[c.lower()] for c in ['ParentName', 'ParentPhone', 'ParentCell', 'ParentEMail', 'ParentAddress', 'ParentCity', 'ParentState', 'ParentZIP',\n",
    "                                                     'Parent2Name', 'Parent2Phone', 'Parent2Cell', 'Parent2Email', 'Parent2Address', 'Parent2City', 'Parent2State', 'Parent2Zip']\n",
    "                    if c.lower() in cols_lower]\n",
    "if existing_columns:\n",
    "    athletes_df.drop(existing_columns, axis=1, inplace=True)\n",
    "    print(\"Parent-related columns removed.\")\n",
    "else:\n",
    "    print(\"No parent-related columns to remove.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4559535d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AthleteId', 'GrpHome', 'Active', 'Sex', 'DateOfBirth', 'SSN', 'HomePhone', 'EmergencyNbr', 'AthleteAddress', 'AthleteCity', 'AthleteState', 'AthleteZip', 'AthleteEMail', 'CounselorName', 'CounselorEMail', 'CounselorPhone', 'AgencyName', 'DrNamePhone', 'Downs', 'AaAx', 'NoXray', 'Photo', 'Na/Rl', 'Allgeries', 'Tetnus', 'Medication', 'Comments', 'MedicalDeadline', 'PhotoRelease', 'AlternatePhone', 'EntryDate', 'TorchRunner', 'AwardsComments', 'Deactivation_Dt', 'name']\n"
     ]
    }
   ],
   "source": [
    "# print just the headers of the DataFrame\n",
    "print(athletes_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8500744d",
   "metadata": {},
   "source": [
    "## Export Counselor Data\n",
    "Create a separate CSV file for counselors, linking them to athletes using AthleteId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0348412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an improved function to split agency name and phone\n",
    "def split_agency_name(agency):\n",
    "    if pd.notna(agency):\n",
    "        # Try different regex patterns to extract phone numbers\n",
    "        # Pattern 1: Name, phone format\n",
    "        match = re.search(r'(.*?)[,/\\s]+(\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{4})$', agency.strip())\n",
    "        if match:\n",
    "            return match.group(1).strip(), match.group(2).strip()\n",
    "        \n",
    "        # Pattern 2: Name/phone format\n",
    "        match = re.search(r'(.*?)[/](\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{4})$', agency.strip())\n",
    "        if match:\n",
    "            return match.group(1).strip(), match.group(2).strip()\n",
    "            \n",
    "        # Pattern 3: Name (phone) format\n",
    "        match = re.search(r'(.*?)\\s*\\(\\s*(\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{4})\\s*\\)', agency.strip())\n",
    "        if match:\n",
    "            return match.group(1).strip(), match.group(2).strip()\n",
    "        \n",
    "        # No phone number found, return just the name\n",
    "        return agency.strip(), None\n",
    "    return None, None\n",
    "\n",
    "# Define a function to normalize agency names (remove trailing commas, etc.)\n",
    "def normalize_agency_name(name):\n",
    "    if pd.notna(name):\n",
    "        # Remove trailing commas, slashes, etc.\n",
    "        return re.sub(r'[,/]$', '', name.strip())\n",
    "    return None\n",
    "\n",
    "# Function to map common agency names to a standard form\n",
    "def standardize_agency_name(name):\n",
    "    if pd.notna(name):\n",
    "        # Map of common variations to standard names\n",
    "        agency_map = {\n",
    "            'Linwood': 'Linwood Center',\n",
    "            'Linwood,': 'Linwood Center',\n",
    "            'ARC': 'Arc of Howard County',\n",
    "            'ARC/': 'Arc of Howard County',\n",
    "            'ARC /': 'Arc of Howard County',\n",
    "            'Athelas': 'Athelas Institute',\n",
    "            'Athelas,': 'Athelas Institute',\n",
    "            'Athlelas,': 'Athelas Institute',\n",
    "            'Athelas Institute,': 'Athelas Institute'\n",
    "        }\n",
    "        \n",
    "        # Check if the name is a known variation\n",
    "        clean_name = normalize_agency_name(name)\n",
    "        if clean_name in agency_map:\n",
    "            return agency_map[clean_name]\n",
    "        return clean_name\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c830eec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in DataFrame: ['AthleteId', 'GrpHome', 'Active', 'Sex', 'DateOfBirth', 'SSN', 'HomePhone', 'EmergencyNbr', 'AthleteAddress', 'AthleteCity', 'AthleteState', 'AthleteZip', 'AthleteEMail', 'CounselorName', 'CounselorEMail', 'CounselorPhone', 'AgencyName', 'DrNamePhone', 'Downs', 'AaAx', 'NoXray', 'Photo', 'Na/Rl', 'Allgeries', 'Tetnus', 'Medication', 'Comments', 'MedicalDeadline', 'PhotoRelease', 'AlternatePhone', 'EntryDate', 'TorchRunner', 'AwardsComments', 'Deactivation_Dt', 'name']\n"
     ]
    }
   ],
   "source": [
    "# Define a function to normalize emails\n",
    "def normalize_email(email):\n",
    "    if pd.notna(email):\n",
    "        return email.strip().lower()\n",
    "    return None\n",
    "\n",
    "# Define a function to split agency name and phone\n",
    "def split_agency_name(agency):\n",
    "    if pd.notna(agency):\n",
    "        # Use regex to extract phone number if present\n",
    "        match = re.search(r'(.*?)(\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{4})$', agency.strip())\n",
    "        if match:\n",
    "            return match.group(1).strip(), match.group(2).strip()\n",
    "        return agency.strip(), None\n",
    "    return None, None\n",
    "\n",
    "# Debug missing columns for counselor data\n",
    "required_columns = ['AthleteId', 'CounselorName', 'CounselorEMail', 'CounselorPhone', 'AgencyName', 'GrpHome']\n",
    "# Print all columns in the DataFrame\n",
    "print(\"Available columns in DataFrame:\", athletes_df.columns.tolist())\n",
    "\n",
    "# Check for missing columns\n",
    "missing_columns = [col for col in required_columns if col not in athletes_df.columns]\n",
    "\n",
    "if missing_columns:\n",
    "    print(f\"Missing columns for counselor data: {missing_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db55056d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counselor data saved to athlete_counselors.csv\n",
      "Dropped counselor columns: ['CounselorName', 'CounselorEMail', 'CounselorPhone', 'AgencyName', 'GrpHome']\n"
     ]
    }
   ],
   "source": [
    "# Create counselors_df from athletes_df\n",
    "counselors_df = athletes_df[['AthleteId', 'CounselorName', 'CounselorEMail', 'AgencyName']].copy()\n",
    "\n",
    "# Rename columns for consistency\n",
    "counselors_df = counselors_df.rename(columns={\n",
    "    'AthleteId': 'id',\n",
    "    'CounselorName': 'name',\n",
    "    'CounselorEMail': 'email'\n",
    "})\n",
    "\n",
    "# Split agency name and phone with improved function\n",
    "counselors_df[['agencyName', 'agencyPhone']] = counselors_df['AgencyName'].apply(lambda x: pd.Series(split_agency_name(x)))\n",
    "\n",
    "# Standardize agency names\n",
    "counselors_df['agencyName'] = counselors_df['agencyName'].apply(standardize_agency_name)\n",
    "\n",
    "# Fill missing agencyPhone with consistent values using the standardized names\n",
    "# First, create a mapping of standard agency names to their most common phone number\n",
    "agency_phone_map = {}\n",
    "for agency, phones in counselors_df.dropna(subset=['agencyName', 'agencyPhone']).groupby('agencyName')['agencyPhone']:\n",
    "    # Get the most common phone number for each agency\n",
    "    phone_counts = phones.value_counts()\n",
    "    if not phone_counts.empty:\n",
    "        agency_phone_map[agency] = phone_counts.index[0]\n",
    "\n",
    "# Then fill in missing phone numbers\n",
    "counselors_df['agencyPhone'] = counselors_df.apply(\n",
    "    lambda row: agency_phone_map.get(row['agencyName'], row['agencyPhone']) \n",
    "    if pd.isna(row['agencyPhone']) else row['agencyPhone'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Remove duplicates based on email and agency\n",
    "counselors_df = counselors_df.drop_duplicates(subset=['email', 'agencyName'])\n",
    "\n",
    "# Save the processed counselors data\n",
    "counselors_df.to_csv('athlete_counselors.csv', index=False)\n",
    "print('Counselor data saved to athlete_counselors.csv')\n",
    "\n",
    "# Drop counselor-related columns from athletes_df since they're now in their own DataFrame\n",
    "counselor_columns = ['CounselorName', 'CounselorEMail', 'CounselorPhone', 'AgencyName', 'GrpHome']\n",
    "# Check which columns exist in the DataFrame before dropping\n",
    "existing_counselor_columns = [col for col in counselor_columns if col in athletes_df.columns]\n",
    "if existing_counselor_columns:\n",
    "    athletes_df.drop(existing_counselor_columns, axis=1, inplace=True)\n",
    "    print(f\"Dropped counselor columns: {existing_counselor_columns}\")\n",
    "else:\n",
    "    print(\"No counselor columns to drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e4258e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AthleteId', 'Active', 'Sex', 'DateOfBirth', 'SSN', 'HomePhone', 'EmergencyNbr', 'AthleteAddress', 'AthleteCity', 'AthleteState', 'AthleteZip', 'AthleteEMail', 'DrNamePhone', 'Downs', 'AaAx', 'NoXray', 'Photo', 'Na/Rl', 'Allgeries', 'Tetnus', 'Medication', 'Comments', 'MedicalDeadline', 'PhotoRelease', 'AlternatePhone', 'EntryDate', 'TorchRunner', 'AwardsComments', 'Deactivation_Dt', 'name']\n"
     ]
    }
   ],
   "source": [
    "print(athletes_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b526d9",
   "metadata": {},
   "source": [
    "## Export Athlete Data\n",
    "Create a separate CSV file for athletes matching the simplified schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09d8a74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'DateOfBirth': ['30-Jan-14' nan '13-Aug-12' ... '06-Aug-18' '14-Sep-09' '03-Apr-02']\n",
      "  DateOfBirth\n",
      "0  01/30/2014\n",
      "1         NaN\n",
      "2  08/13/2012\n",
      "3  09/25/2001\n",
      "4  11/20/1983\n"
     ]
    }
   ],
   "source": [
    "# Inspect and clean 'DateOfBirth' column\n",
    "if 'DateOfBirth' in athletes_df.columns:\n",
    "    # Display unique values in 'DateOfBirth' to identify invalid entries\n",
    "    print(\"Unique values in 'DateOfBirth':\", athletes_df['DateOfBirth'].unique())\n",
    "\n",
    "    # Replace invalid or missing values with NaN\n",
    "    athletes_df['DateOfBirth'] = athletes_df['DateOfBirth'].replace(['', 'None', 'N/A', 'NaN'], pd.NA)\n",
    "\n",
    "    # Convert 'DateOfBirth' to datetime\n",
    "    athletes_df['DateOfBirth'] = pd.to_datetime(athletes_df['DateOfBirth'], errors='coerce', format='%d-%b-%y')\n",
    "\n",
    "    # Adjust years between 20-99 to 19XX\n",
    "    def fix_year(date):\n",
    "        if pd.isna(date):\n",
    "            return None\n",
    "        if date.year > 2020:  # Adjust years above 2020 to 19XX\n",
    "            return date.replace(year=date.year - 100)\n",
    "        return date\n",
    "\n",
    "    athletes_df['DateOfBirth'] = athletes_df['DateOfBirth'].apply(lambda x: fix_year(x))\n",
    "\n",
    "    # Ensure 'DateOfBirth' contains valid datetime values before formatting\n",
    "    if pd.api.types.is_datetime64_any_dtype(athletes_df['DateOfBirth']):\n",
    "        # Format 'DateOfBirth' to MM/DD/YYYY\n",
    "        athletes_df['DateOfBirth'] = athletes_df['DateOfBirth'].dt.strftime('%m/%d/%Y')\n",
    "    else:\n",
    "        print(\"Error: 'DateOfBirth' column does not contain valid datetime values after cleaning.\")\n",
    "\n",
    "    # Display the first few rows to verify the changes\n",
    "    print(athletes_df[['DateOfBirth']].head())\n",
    "else:\n",
    "    print(\"Error: 'DateOfBirth' column is missing in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e763ae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Athlete data saved to athletes_simplified.csv\n"
     ]
    }
   ],
   "source": [
    "# Ensure the required columns exist before extracting athlete data\n",
    "required_columns = ['AthleteId', 'name', 'Sex', 'DateOfBirth', 'AthleteEMail', 'HomePhone', 'EmergencyNbr',\n",
    "                    'AthleteAddress', 'AthleteCity', 'AthleteState', 'AthleteZip', 'Active', 'MedicalDeadline']\n",
    "missing_columns = [col for col in required_columns if col not in athletes_df.columns]\n",
    "if missing_columns:\n",
    "    print(f\"Missing columns in DataFrame: {missing_columns}\")\n",
    "else:\n",
    "    # Extract athlete data matching the simplified schema\n",
    "    athletes_schema_df = athletes_df[required_columns].copy()\n",
    "\n",
    "    # Define a function to normalize phone numbers (extract only digits)\n",
    "    def normalize_phone(phone):\n",
    "        if pd.isna(phone) or phone == '':\n",
    "            return ''\n",
    "        # Extract only digits from the phone number\n",
    "        return ''.join(filter(str.isdigit, str(phone)))\n",
    "    \n",
    "    # Normalize phone numbers before renaming\n",
    "    athletes_schema_df['HomePhone'] = athletes_schema_df['HomePhone'].apply(normalize_phone)\n",
    "    athletes_schema_df['EmergencyNbr'] = athletes_schema_df['EmergencyNbr'].apply(normalize_phone)\n",
    "    \n",
    "    # Rename columns to match the schema\n",
    "    athletes_schema_df.rename(columns={\n",
    "        'AthleteId': 'id',\n",
    "        'Sex': 'gender',\n",
    "        'DateOfBirth': 'dateOfBirth',\n",
    "        'AthleteEMail': 'email',\n",
    "        'HomePhone': 'primary_phone',  # Changed from 'phone' to 'primary_phone'\n",
    "        'EmergencyNbr': 'secondary_phone',  # Added emergency number as secondary phone\n",
    "        'AthleteAddress': 'street',\n",
    "        'AthleteCity': 'city',\n",
    "        'AthleteState': 'state',\n",
    "        'AthleteZip': 'zip',\n",
    "        'Active': 'status',\n",
    "        'MedicalDeadline': 'medicalStatus'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Convert 'status' to a more descriptive format\n",
    "    athletes_schema_df['status'] = athletes_schema_df['status'].apply(lambda x: 'Active' if x else 'Inactive')\n",
    "\n",
    "    # Format medical status dates from \"28-Mar-21\" to \"03/04/2023\" format\n",
    "    def format_medical_date(date_str):\n",
    "        if pd.isna(date_str) or date_str == '':\n",
    "            return ''\n",
    "        try:\n",
    "            # Parse the date string\n",
    "            date_obj = pd.to_datetime(date_str, format='%d-%b-%y', errors='coerce')\n",
    "            if pd.isna(date_obj):\n",
    "                return date_str\n",
    "            \n",
    "            # Format as MM/DD/YYYY\n",
    "            return date_obj.strftime('%m/%d/%Y')\n",
    "        except:\n",
    "            return date_str\n",
    "    \n",
    "    athletes_schema_df['medicalStatus'] = athletes_schema_df['medicalStatus'].apply(format_medical_date)\n",
    "\n",
    "    # Save to a new CSV file\n",
    "    athletes_schema_df.to_csv('athletes_simplified.csv', index=False)\n",
    "    print('Athlete data saved to athletes_simplified.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425af002",
   "metadata": {},
   "source": [
    "## Drop Simplified Athlete Columns\n",
    "Remove columns that were exported to `athletes_simplified.csv`, excluding `name` and `AthleteId`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1b3bb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['Sex', 'DateOfBirth', 'AthleteEMail', 'HomePhone', 'AthleteAddress', 'AthleteCity', 'AthleteState', 'AthleteZip', 'Active', 'MedicalDeadline']\n",
      "Remaining headers: ['AthleteId', 'SSN', 'EmergencyNbr', 'DrNamePhone', 'Downs', 'AaAx', 'NoXray', 'Photo', 'Na/Rl', 'Allgeries', 'Tetnus', 'Medication', 'Comments', 'PhotoRelease', 'AlternatePhone', 'EntryDate', 'TorchRunner', 'AwardsComments', 'Deactivation_Dt', 'name']\n"
     ]
    }
   ],
   "source": [
    "# Define columns to drop (excluding 'name' and 'AthleteId')\n",
    "columns_to_drop = ['Sex', 'DateOfBirth', 'AthleteEMail', 'HomePhone',\n",
    "                   'AthleteAddress', 'AthleteCity', 'AthleteState', 'AthleteZip', 'Active', 'MedicalDeadline']\n",
    "\n",
    "\n",
    "# Drop columns if they exist in the DataFrame\n",
    "existing_columns = [col for col in columns_to_drop if col in athletes_df.columns]\n",
    "if existing_columns:\n",
    "    athletes_df.drop(existing_columns, axis=1, inplace=True)\n",
    "    print(f\"Dropped columns: {existing_columns}\")\n",
    "else:\n",
    "    print(\"No matching columns to drop.\")\n",
    "\n",
    "# Print the remaining headers of the DataFrame\n",
    "print('Remaining headers:', athletes_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e52fac5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Athlete comments CSV exported as athlete_comments.csv\n",
      "Dropped comments columns from athletes_df\n",
      "Remaining headers: ['AthleteId', 'SSN', 'EmergencyNbr', 'DrNamePhone', 'Downs', 'AaAx', 'NoXray', 'Photo', 'Na/Rl', 'Allgeries', 'Tetnus', 'Medication', 'PhotoRelease', 'AlternatePhone', 'EntryDate', 'TorchRunner', 'Deactivation_Dt', 'name']\n"
     ]
    }
   ],
   "source": [
    "# Export remaining headers into their own CSV, splitting normal and award comments\n",
    "if 'Comments' in athletes_df.columns and 'AwardsComments' in athletes_df.columns:\n",
    "    comments_df = athletes_df[['AthleteId', 'Comments', 'AwardsComments']].copy()\n",
    "    comments_df.rename(columns={\n",
    "        'Comments': 'normal_comments',\n",
    "        'AwardsComments': 'award_comments'\n",
    "    }, inplace=True)\n",
    "    comments_df.to_csv('athlete_comments.csv', index=False)\n",
    "    print('Athlete comments CSV exported as athlete_comments.csv')\n",
    "    athletes_df.drop(['Comments', 'AwardsComments'], axis=1, inplace=True)\n",
    "    print('Dropped comments columns from athletes_df')\n",
    "else:\n",
    "    print('No comment columns found to export or drop')\n",
    "\n",
    "print('Remaining headers:', athletes_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90af95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cfc160b",
   "metadata": {},
   "source": [
    "## Extract Medical Data\n",
    "Create a separate DataFrame for medical information including doctor details and allergies/medication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32532acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical data saved to athlete_medical.csv\n",
      "\n",
      "Sample of medical data:\n",
      "     id         doctor_name doctor_phone          Allgeries  \\\n",
      "0  1445  Dr. Michelle Mcwan   4434511600                NaN   \n",
      "1  1320                None                             NaN   \n",
      "2  1477       Dr. L. Berger   4104657550                NaN   \n",
      "3  1034         Dr. Hashimi   4109972770                NaN   \n",
      "4    18       Dr. Alice Lee               augmentin, gluten   \n",
      "\n",
      "                                          Medication  \n",
      "0  Zoloft, 75mg, qd\\nClanidine, 2mg, qhs\\nExlax, ...  \n",
      "1                                                NaN  \n",
      "2                                                NaN  \n",
      "3  insulin aspert, 3xday\\ndexem G7, every 10days\\...  \n",
      "4  clonazapam, 0.5mg, 2xday\\nLevothyroxine, 50mcg...  \n",
      "\n",
      "Dropped medical columns: ['DrNamePhone', 'Allgeries', 'Medication', 'Downs', 'AaAx', 'NoXray', 'Tetnus']\n",
      "\n",
      "Remaining headers: ['AthleteId', 'SSN', 'EmergencyNbr', 'Photo', 'Na/Rl', 'PhotoRelease', 'AlternatePhone', 'EntryDate', 'TorchRunner', 'Deactivation_Dt', 'name']\n"
     ]
    }
   ],
   "source": [
    "# Define a function to split doctor name and phone number\n",
    "def split_doctor_info(doctor_info):\n",
    "    if pd.isna(doctor_info) or doctor_info == '':\n",
    "        return None, None\n",
    "    \n",
    "    # Common pattern: \"Dr. Name, Phone Number\"\n",
    "    match = re.search(r'(.*?)(?:,\\s*(\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{4}))?$', doctor_info.strip())\n",
    "    if match:\n",
    "        name = match.group(1).strip() if match.group(1) else None\n",
    "        phone = match.group(2).strip() if match.group(2) else None\n",
    "        return name, phone\n",
    "    else:\n",
    "        return doctor_info, None\n",
    "\n",
    "# Create medical_df from athletes_df with required columns\n",
    "medical_columns = ['AthleteId', 'DrNamePhone', 'Allgeries', 'Medication']\n",
    "medical_df = athletes_df[medical_columns].copy()\n",
    "\n",
    "# Rename AthleteId to id\n",
    "medical_df.rename(columns={'AthleteId': 'id'}, inplace=True)\n",
    "\n",
    "# Split DrNamePhone into doctor_name and doctor_phone\n",
    "medical_df[['doctor_name', 'doctor_phone']] = medical_df['DrNamePhone'].apply(lambda x: pd.Series(split_doctor_info(x)))\n",
    "\n",
    "# Normalize the doctor_phone column and ensure it's a string\n",
    "medical_df['doctor_phone'] = medical_df['doctor_phone'].apply(lambda x: str(normalize_phone(x)) if x else '')\n",
    "\n",
    "# Drop the original DrNamePhone column\n",
    "medical_df.drop('DrNamePhone', axis=1, inplace=True)\n",
    "\n",
    "# Reorder columns to match the desired format\n",
    "medical_df = medical_df[['id', 'doctor_name', 'doctor_phone', 'Allgeries', 'Medication']]\n",
    "\n",
    "# Save the medical data to a CSV file\n",
    "medical_df.to_csv('athlete_medical.csv', index=False)\n",
    "print('Medical data saved to athlete_medical.csv')\n",
    "\n",
    "# Display a sample of the medical data\n",
    "print(\"\\nSample of medical data:\")\n",
    "print(medical_df.head())\n",
    "\n",
    "# Drop the medical columns from the athletes_df since they are now in their own file\n",
    "medical_columns_to_drop = ['DrNamePhone', 'Allgeries', 'Medication', 'Downs', 'AaAx', 'NoXray', 'Tetnus']\n",
    "existing_medical_columns = [col for col in medical_columns_to_drop if col in athletes_df.columns]\n",
    "if existing_medical_columns:\n",
    "    athletes_df.drop(existing_medical_columns, axis=1, inplace=True)\n",
    "    print(f\"\\nDropped medical columns: {existing_medical_columns}\")\n",
    "else:\n",
    "    print(\"\\nNo medical columns to drop\")\n",
    "\n",
    "# Print remaining columns\n",
    "print(\"\\nRemaining headers:\", athletes_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2841d6da",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3237fd2",
   "metadata": {},
   "source": [
    "# Generate Nested JSON from CSVs\n",
    "This section generates a nested JSON file from the exported CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c771db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1150 athletes from simplified CSV\n",
      "Loaded 1150 medical records\n",
      "Loaded 70 counselor records\n",
      "Loaded 1150 comment records\n",
      "Loaded 772 parent records\n",
      "Created nested JSON file with 1150 athletes\n",
      "\n",
      "Sample of first athlete in nested JSON:\n",
      "{\n",
      "    \"id\": 1445,\n",
      "    \"name\": NaN,\n",
      "    \"gender\": \"F\",\n",
      "    \"dateOfBirth\": \"01/30/2014\",\n",
      "    \"email\": NaN,\n",
      "    \"primary_phone\": \"\",\n",
      "    \"secondary_phone\": \"\",\n",
      "    \"street\": \"7036 Foxton Way\",\n",
      "    \"city\": \"Hanover\",\n",
      "    \"state\": \"MD\",\n",
      "    \"zip\": \"21076\",\n",
      "    \"status\": \"Active\",\n",
      "    \"medicalStatus\": \"03/05/2027\",\n",
      "    \"medical\": {\n",
      "        \"doctor_name\": \"Dr. Michelle Mcwan\",\n",
      "        \"doctor_phone\": \"4434511600\",\n",
      "        \"Allgeries\": NaN,\n",
      "        \"Medication\": \"Zoloft, 75mg, qd\\nClanidine, 2mg, qhs\\nExlax, 1tablet, qd\\nMiralas, 1 cap, qd\"\n",
      "    },\n",
      "    \"counselor\": {\n",
      "        \"name\": NaN,\n",
      "        \"email\": NaN,\n",
      "        \"AgencyName\": NaN,\n",
      "        \"agencyName\": NaN,\n",
      "        \"agencyPhone\": \"\"\n",
      "    },\n",
      "    \"comments\": {\n",
      "        \"normal_comments\": \"Autism\",\n",
      "        \"award_comments\": NaN\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# First, let's create the initial nested JSON file from our CSV files\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to fix phone numbers (convert floats to strings without decimals)\n",
    "def fix_phone_format(value):\n",
    "    if pd.isna(value):\n",
    "        return \"\"\n",
    "    if isinstance(value, (int, float)):\n",
    "        return str(int(value))  # Convert to int first to remove .0, then to string\n",
    "    return str(value)\n",
    "\n",
    "# Load the simplified athletes data\n",
    "try:\n",
    "    athletes_df = pd.read_csv('athletes_simplified.csv', encoding='latin1')\n",
    "    print(f\"Loaded {len(athletes_df)} athletes from simplified CSV\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: athletes_simplified.csv not found\")\n",
    "    athletes_df = pd.DataFrame()\n",
    "\n",
    "# Fix phone numbers in athletes dataframe\n",
    "if not athletes_df.empty:\n",
    "    if 'primary_phone' in athletes_df.columns:\n",
    "        athletes_df['primary_phone'] = athletes_df['primary_phone'].apply(fix_phone_format)\n",
    "    if 'secondary_phone' in athletes_df.columns:\n",
    "        athletes_df['secondary_phone'] = athletes_df['secondary_phone'].apply(fix_phone_format)\n",
    "\n",
    "# Load the medical data\n",
    "try:\n",
    "    medical_df = pd.read_csv('athlete_medical.csv', encoding='latin1')\n",
    "    print(f\"Loaded {len(medical_df)} medical records\")\n",
    "    # Fix doctor phone numbers\n",
    "    if 'doctor_phone' in medical_df.columns:\n",
    "        medical_df['doctor_phone'] = medical_df['doctor_phone'].apply(fix_phone_format)\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: athlete_medical.csv not found\")\n",
    "    medical_df = pd.DataFrame()\n",
    "\n",
    "# Load the counselors data\n",
    "try:\n",
    "    counselors_df = pd.read_csv('athlete_counselors.csv', encoding='latin1')\n",
    "    print(f\"Loaded {len(counselors_df)} counselor records\")\n",
    "    # Fix phone numbers in counselors_df\n",
    "    if 'agencyPhone' in counselors_df.columns:\n",
    "        counselors_df['agencyPhone'] = counselors_df['agencyPhone'].apply(fix_phone_format)\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: athlete_counselors.csv not found\")\n",
    "    counselors_df = pd.DataFrame()\n",
    "\n",
    "# Load the comments data\n",
    "try:\n",
    "    comments_df = pd.read_csv('athlete_comments.csv', encoding='latin1')\n",
    "    print(f\"Loaded {len(comments_df)} comment records\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: athlete_comments.csv not found\")\n",
    "    comments_df = pd.DataFrame()\n",
    "\n",
    "# Load the parents data\n",
    "try:\n",
    "    parents_df = pd.read_csv('athlete_parents.csv', encoding='latin1')\n",
    "    print(f\"Loaded {len(parents_df)} parent records\")\n",
    "    # Fix phone numbers in parents_df\n",
    "    if 'primaryPhone' in parents_df.columns:\n",
    "        parents_df['primaryPhone'] = parents_df['primaryPhone'].apply(fix_phone_format)\n",
    "    if 'secondaryPhone' in parents_df.columns:\n",
    "        parents_df['secondaryPhone'] = parents_df['secondaryPhone'].apply(fix_phone_format)\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: athlete_parents.csv not found\")\n",
    "    parents_df = pd.DataFrame()\n",
    "\n",
    "# Custom JSON serializer to handle different types\n",
    "def custom_json_serializer(obj):\n",
    "    if isinstance(obj, (np.integer)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating)):\n",
    "        return str(int(obj)) if obj.is_integer() else str(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif pd.isna(obj):\n",
    "        return \"\"\n",
    "    return obj\n",
    "\n",
    "# Now create a nested JSON structure\n",
    "nested_athletes = []\n",
    "\n",
    "# Process each athlete\n",
    "if not athletes_df.empty:\n",
    "    for _, athlete in athletes_df.iterrows():\n",
    "        athlete_id = athlete['id']\n",
    "        athlete_dict = athlete.to_dict()\n",
    "        \n",
    "        # Add medical information if available\n",
    "        if not medical_df.empty and 'id' in medical_df.columns:\n",
    "            medical_records = medical_df[medical_df['id'] == athlete_id]\n",
    "            if not medical_records.empty:\n",
    "                medical_info = medical_records.iloc[0].to_dict()\n",
    "                # Remove id to avoid duplication\n",
    "                if 'id' in medical_info:\n",
    "                    del medical_info['id']\n",
    "                athlete_dict['medical'] = medical_info\n",
    "        \n",
    "        # Add counselor information if available\n",
    "        if not counselors_df.empty and 'id' in counselors_df.columns:\n",
    "            counselor_records = counselors_df[counselors_df['id'] == athlete_id]\n",
    "            if not counselor_records.empty:\n",
    "                counselor_info = counselor_records.iloc[0].to_dict()\n",
    "                # Remove id to avoid duplication\n",
    "                if 'id' in counselor_info:\n",
    "                    del counselor_info['id']\n",
    "                athlete_dict['counselor'] = counselor_info\n",
    "        \n",
    "        # Add comments if available\n",
    "        if not comments_df.empty:\n",
    "            comment_records = comments_df[comments_df['AthleteId'] == athlete_id]\n",
    "            if not comment_records.empty:\n",
    "                comment_info = comment_records.iloc[0].to_dict()\n",
    "                # Remove id to avoid duplication\n",
    "                if 'AthleteId' in comment_info:\n",
    "                    del comment_info['AthleteId']\n",
    "                athlete_dict['comments'] = comment_info\n",
    "        \n",
    "        # Add parents as an array if available\n",
    "        if not parents_df.empty:\n",
    "            parent_records = parents_df[parents_df['id'] == athlete_id]\n",
    "            if not parent_records.empty:\n",
    "                parents_list = []\n",
    "                for _, parent in parent_records.iterrows():\n",
    "                    parent_info = parent.to_dict()\n",
    "                    # Remove athlete id to avoid duplication\n",
    "                    if 'id' in parent_info:\n",
    "                        del parent_info['id']\n",
    "                    parents_list.append(parent_info)\n",
    "                athlete_dict['parents'] = parents_list\n",
    "        \n",
    "        nested_athletes.append(athlete_dict)\n",
    "\n",
    "# Write the nested data to a JSON file\n",
    "json_file_path = 'athletes_nested.json'\n",
    "with open(json_file_path, 'w') as f:\n",
    "    json.dump(nested_athletes, f, indent=4, default=custom_json_serializer)\n",
    "\n",
    "print(f\"Created nested JSON file with {len(nested_athletes)} athletes\")\n",
    "\n",
    "# Display a sample of the nested data if available\n",
    "if nested_athletes:\n",
    "    print(\"\\nSample of first athlete in nested JSON:\")\n",
    "    print(json.dumps(nested_athletes[0], indent=4, default=custom_json_serializer))\n",
    "else:\n",
    "    print(\"No athletes to include in nested JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dc6314d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1150 athletes. Final count: 1147.\n",
      "Sample processed athlete:\n",
      "{\n",
      "    \"id\": 1034,\n",
      "    \"name\": \"Mona Abdelhalim\",\n",
      "    \"gender\": \"F\",\n",
      "    \"dateOfBirth\": \"09/25/2001\",\n",
      "    \"email\": \"\",\n",
      "    \"primary_phone\": \"4102824201\",\n",
      "    \"secondary_phone\": \"\",\n",
      "    \"street\": \"8338 Goverenor Grayson Way\",\n",
      "    \"city\": \"Ellicott City\",\n",
      "    \"state\": \"MD\",\n",
      "    \"zip\": \"21043\",\n",
      "    \"status\": \"Active\",\n",
      "    \"medicalStatus\": \"08/14/2027\",\n",
      "    \"medical\": {\n",
      "        \"doctor_name\": \"Dr. Hashimi\",\n",
      "        \"doctor_phone\": \"4109972770\",\n",
      "        \"Allgeries\": \"\",\n",
      "        \"Medication\": \"insulin aspert, 3xday\\ndexem G7, every 10days\\nLevomyroxine, 175mg, 1xday\\nmelatonin, 1xday\\nfiber, 1xday\\nmultivitamin, 1xday\\nsuper green, black see, curcumin, cinamin\"\n",
      "    },\n",
      "    \"comments\": {\n",
      "        \"normal_comments\": \"\",\n",
      "        \"award_comments\": \"\"\n",
      "    },\n",
      "    \"parents\": [\n",
      "        {\n",
      "            \"name\": \"Fatima H Kahil\",\n",
      "            \"primaryPhone\": \"4102824201\",\n",
      "            \"secondaryPhone\": \"4108317156\",\n",
      "            \"email\": \"fatmakhalil12@yahoo.com\",\n",
      "            \"street\": \"\",\n",
      "            \"city\": \"\",\n",
      "            \"state\": \"\",\n",
      "            \"zip\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import re\n",
    "\n",
    "json_file_path = 'athletes_nested.json'\n",
    "\n",
    "# Step 1: Read the file content as a string\n",
    "try:\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        file_content = f.read()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File {json_file_path} not found.\")\n",
    "    # Create an empty list if file not found to avoid further errors, or handle appropriately\n",
    "    file_content = '[]'\n",
    "\n",
    "# Step 2: Replace standalone NaN with null to make it valid JSON\n",
    "# Using regex to replace whole word NaN only, avoiding accidental replacement in strings like 'Nancy'\n",
    "valid_json_content = re.sub(r'\\bNaN\\b', 'null', file_content)\n",
    "\n",
    "# Step 3: Parse the modified string\n",
    "try:\n",
    "    all_athletes_data = json.loads(valid_json_content)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error decoding JSON: {e}\")\n",
    "    all_athletes_data = []  # Default to empty list on error\n",
    "\n",
    "original_athlete_count = len(all_athletes_data)\n",
    "\n",
    "# Step 4 & 5: Define a recursive function to replace None (originally NaN/null) with ''\n",
    "def replace_none_deep(item):\n",
    "    if item is None:\n",
    "        return ''\n",
    "    elif isinstance(item, dict):\n",
    "        return {k: replace_none_deep(v) for k, v in item.items()}\n",
    "    elif isinstance(item, list):\n",
    "        return [replace_none_deep(elem) for elem in item]\n",
    "    elif isinstance(item, float) and math.isnan(item):\n",
    "        return ''\n",
    "    return item\n",
    "\n",
    "processed_athletes = []\n",
    "for athlete in all_athletes_data:\n",
    "    if not isinstance(athlete, dict):  # Skip if an entry is not a dictionary\n",
    "        print(f\"Skipping non-dictionary entry: {athlete}\")\n",
    "        continue\n",
    "\n",
    "    # Check for missing name\n",
    "    name = athlete.get('name')\n",
    "\n",
    "    # A field is considered 'missing' for filtering if it's None (originally NaN/null)\n",
    "    is_name_missing = name is None\n",
    "\n",
    "    if is_name_missing:\n",
    "        continue  # Skip this athlete\n",
    "    else:\n",
    "        # Replace all None values (originally NaN/null) with empty strings\n",
    "        cleaned_athlete = replace_none_deep(athlete)\n",
    "        processed_athletes.append(cleaned_athlete)\n",
    "\n",
    "final_athlete_count = len(processed_athletes)\n",
    "\n",
    "# Step 6: Write the processed data back to the JSON file\n",
    "with open(json_file_path, 'w') as f:\n",
    "    json.dump(processed_athletes, f, indent=4)\n",
    "\n",
    "print(f\"Processed {original_athlete_count} athletes. Final count: {final_athlete_count}.\")\n",
    "if processed_athletes:\n",
    "    print(\"Sample processed athlete:\")\n",
    "    print(json.dumps(processed_athletes[0], indent=4))\n",
    "else:\n",
    "    print(\"No valid athletes found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
