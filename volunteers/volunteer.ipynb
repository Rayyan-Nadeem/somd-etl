{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28abcec8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'etl_env (Python -1.-1.-1)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f07e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "volunteer_df = pd.read_csv('volunteers.csv', encoding='latin1')\n",
    "print(volunteer_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6f62a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def normalize_email(email):\n",
    "\n",
    "#  Normalize phone numbers: remove non-numeric characters\n",
    "def normalize_phone(phone):\n",
    "    if pd.isna(phone):\n",
    "        return 'N/A'\n",
    "    return ''.join(filter(str.isdigit, str(phone)))\n",
    "\n",
    "#if empty or not a number set to 0000000000\n",
    "def fix_phone_format(phone):\n",
    "    if pd.isna(phone) or not phone.isdigit() or len(phone) < 10:\n",
    "        return '0000000000'\n",
    "    return phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df2364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if first name or last name are empty, delete the row\n",
    "volunteer_df.dropna(subset=['First', 'Last'], how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dc8025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize email addresses: convert to lowercase and default to 'na@test.com'\n",
    "volunteer_df.rename(columns={'EMail': 'email'}, inplace=True)\n",
    "volunteer_df['email'] = volunteer_df['email'].str.lower().fillna('na@test.com')\n",
    "print(volunteer_df[['email']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4c72b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "volunteer_df['HomePhone'] = volunteer_df['HomePhone'].apply(normalize_phone)\n",
    "volunteer_df['WorkPhone'] = volunteer_df['WorkPhone'].apply(normalize_phone)\n",
    "volunteer_df['CellPhone'] = volunteer_df['CellPhone'].apply(normalize_phone)\n",
    "print(volunteer_df[['HomePhone', 'WorkPhone', 'CellPhone']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bccee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prioritize phone numbers: home and cell first, work last\n",
    "def prioritize_phone(row):\n",
    "    # Return the first available phone number from the priority list\n",
    "    for phone in [row['HomePhone'], row['CellPhone'], row['WorkPhone']]:\n",
    "        if phone != 'N/A' and phone: # Check for 'N/A' and empty strings\n",
    "            return phone\n",
    "    return 'N/A' # Return 'N/A' if no valid phone is found\n",
    "\n",
    "volunteer_df['phone'] = volunteer_df.apply(prioritize_phone, axis=1)\n",
    "\n",
    "\n",
    "# go through the phone column and apply the fix_phone_format function\n",
    "if 'phone' in volunteer_df.columns:\n",
    "    volunteer_df['phone'] = volunteer_df['phone'].apply(fix_phone_format)\n",
    "\n",
    "\n",
    "# Remove old phone number columns\n",
    "volunteer_df.drop(columns=['HomePhone', 'WorkPhone', 'CellPhone'], inplace=True)\n",
    "\n",
    "print(volunteer_df[['phone']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b982ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'Current' to 'Active' and ensure it's boolean\n",
    "volunteer_df = volunteer_df.rename(columns={'Current': 'Active'})\n",
    "volunteer_df['Active'] = volunteer_df['Active'].astype(bool)\n",
    "print(volunteer_df[['Active']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize address fields and add sex\n",
    "defaults = {\n",
    "    'Street': '123 Main St',\n",
    "    'City': 'Anytown',\n",
    "    'State': 'NY',\n",
    "    'ZipCode': '20000'\n",
    "}\n",
    "for col, default in defaults.items():\n",
    "    if col in volunteer_df.columns:\n",
    "        volunteer_df[col] = volunteer_df[col].fillna('').replace(['', 'nan', 'N/A', 'None', pd.NA], default)\n",
    "\n",
    "# Add 'sex' column, default to 'Other' if not present\n",
    "if 'sex' not in volunteer_df.columns:\n",
    "    volunteer_df['sex'] = 'Other'\n",
    "else:\n",
    "    volunteer_df['sex']\n",
    "    volunteer_df['sex'] = volunteer_df['sex'].fillna('Other').replace('', 'Other')\n",
    "\n",
    "print(volunteer_df[['Street', 'City', 'State', 'ZipCode', 'sex']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7623ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix 'dateOfBirth' to handle years correctly\n",
    "volunteer_df.rename(columns={'Birthdate': 'dateOfBirth'}, inplace=True)\n",
    "\n",
    "# Convert 'dateOfBirth' to datetime\n",
    "volunteer_df['dateOfBirth'] = pd.to_datetime(volunteer_df['dateOfBirth'], errors='coerce', format='%d-%b-%y')\n",
    "\n",
    "# Adjust years between 20-99 to 19XX\n",
    "def fix_year(date):\n",
    "    if pd.isna(date):\n",
    "        return None\n",
    "    if date.year > 2020:  # Adjust years above 2020 to 19XX\n",
    "        return date.replace(year=date.year - 100)\n",
    "    return date\n",
    "\n",
    "volunteer_df['dateOfBirth'] = volunteer_df['dateOfBirth'].apply(lambda x: fix_year(pd.to_datetime(x, errors='coerce')))\n",
    "\n",
    "# Format 'dateOfBirth' to MM/DD/YYYY\n",
    "volunteer_df['dateOfBirth'] = volunteer_df['dateOfBirth'].dt.strftime('%m/%d/%Y')\n",
    "# If dateOfBirth is empty or NaN, set to '01/01/1900'\n",
    "if 'dateOfBirth' in volunteer_df.columns:\n",
    "    volunteer_df['dateOfBirth'] = volunteer_df['dateOfBirth'].fillna('01/01/1900').replace('', '01/01/1900')\n",
    "print(volunteer_df[['dateOfBirth']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0918f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnecessary columns\n",
    "volunteer_df = volunteer_df.drop(columns=['Classification', 'LastVolDate', 'OneDayEvent', 'LastContact',\n",
    "                'Competitions', 'Guide', 'Fundraising', 'Coach', 'Office', 'SportsMgmt', 'Medical', 'PublicRelations', 'CoAdmin'\n",
    "])\n",
    "\n",
    "print(volunteer_df.columns.tolist())\n",
    "\n",
    "# rename ApplicationDate to 'applicationCertificationDate'\n",
    "if 'ApplicationDate' in volunteer_df.columns:\n",
    "    volunteer_df = volunteer_df.rename(columns={'ApplicationDate': 'applicationCertificationDate'})\n",
    "    # default to '01/01/1900' if empty\n",
    "    volunteer_df['applicationCertificationDate'] = volunteer_df['applicationCertificationDate'].fillna('01/01/1900').replace('', '01/01/1900')\n",
    "\n",
    "# add 'CSOA-certificationData' column to volunteer_df with default ''\n",
    "volunteer_df['CSOA-certificationData'] = \"\"\n",
    "\n",
    "# add concussion training date with default ''\n",
    "volunteer_df['Concussion-certificationData'] = \"\"\n",
    "\n",
    "# Add OrientationDate with default ''\n",
    "volunteer_df['OrientationDate'] = volunteer_df.get('OrientationDate', pd.Series([''] * len(volunteer_df))).fillna('').replace('')\n",
    "\n",
    "#rname VOLid to id\n",
    "if 'VolId' in volunteer_df.columns:\n",
    "    volunteer_df = volunteer_df.rename(columns={'VolId': 'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174bbea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'LastContact', to datetime\n",
    "volunteer_df['PBC Expir Date'] = pd.to_datetime(volunteer_df['PBC Expir Date'], errors='coerce')\n",
    "\n",
    "print(volunteer_df[['PBC Expir Date']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaebb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split comments into a separate DataFrame\n",
    "comments_df = volunteer_df[['id', 'Comments', 'GeneralComments']].copy()\n",
    "\n",
    "\n",
    "# Include 'LastVolEvent' in the comments DataFrame\n",
    "comments_df['LastVolEvent'] = volunteer_df['LastVolEvent']\n",
    "\n",
    "# Drop 'LastVolEvent' from the main DataFrame\n",
    "final_df = volunteer_df.drop(columns=['Comments', 'GeneralComments', 'LastVolEvent'])\n",
    "comments_df.to_csv('volunteer_comments.csv', index=False)\n",
    "print(\"Comments data exported to 'volunteer_comments.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978e37da",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('final_volunteer_data.csv', index=False)\n",
    "print(\\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e727d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to fix phone numbers (convert floats to strings without decimals)\n",
    "def fix_phone_format(value):\n",
    "    if pd.isna(value):\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# Custom JSON serializer to handle different types\n",
    "def custom_json_serializer(obj):\n",
    "    if pd.isna(obj) or obj is pd.NaT:  # Check for NaN/NaT first\n",
    "        return \"\"\n",
    "    elif isinstance(obj, (np.integer)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating)):\n",
    "        # NaN is already handled by the pd.isna() check above.\n",
    "        # This branch is for actual float numbers.\n",
    "        return str(int(obj)) if obj.is_integer() else str(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, (pd.Timestamp)):\n",
    "        return obj.strftime('%m/%d/%Y') # Format dates as MM/DD/YYYY\n",
    "    return obj\n",
    "\n",
    "# Load the processed volunteer data\n",
    "try:\n",
    "    volunteers_df = pd.read_csv('final_volunteer_data.csv', encoding='latin1')\n",
    "    print(f\"Loaded {len(volunteers_df)} volunteers from final_volunteer_data.csv\")\n",
    "\n",
    "    # Convert relevant date columns to datetime objects for proper serialization\n",
    "    date_columns_to_parse = ['ApplicationDate', 'LastVolDate', 'LastContact', 'AttendedOrientation', 'PBC Expir Date', 'CSOA-certificationData', 'Concussion-certificationData']\n",
    "    for col in date_columns_to_parse:\n",
    "        if col in volunteers_df.columns:\n",
    "            volunteers_df[col] = pd.to_datetime(volunteers_df[col], errors='coerce')\n",
    "            \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: final_volunteer_data.csv not found\")\n",
    "    volunteers_df = pd.DataFrame()\n",
    "\n",
    "# Ensure phone is a string when writing out\n",
    "volunteers_df['phone'] = volunteers_df['phone'].astype(str)\n",
    "\n",
    "# Load the volunteer comments data\n",
    "try:\n",
    "    volunteer_comments_df = pd.read_csv('volunteer_comments.csv', encoding='latin1')\n",
    "    print(f\"Loaded {len(volunteer_comments_df)} volunteer comment records\")\n",
    "    # Replace all NaN values in the comments DataFrame with empty strings\n",
    "    volunteer_comments_df = volunteer_comments_df.fillna(\"\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: volunteer_comments.csv not found\")\n",
    "    volunteer_comments_df = pd.DataFrame().fillna(\"\") # Ensure empty df also has no NaNs if used later\n",
    "\n",
    "# Create a nested JSON structure for volunteers\n",
    "nested_volunteers = []\n",
    "\n",
    "if not volunteers_df.empty:\n",
    "    for _, volunteer in volunteers_df.iterrows():\n",
    "        volunteer_id = volunteer['id']\n",
    "        volunteer_dict = volunteer.to_dict()\n",
    "        \n",
    "        # Add comments if available\n",
    "        if not volunteer_comments_df.empty and 'id' in volunteer_comments_df.columns:\n",
    "            comment_records = volunteer_comments_df[volunteer_comments_df['id'] == volunteer_id]\n",
    "            if not comment_records.empty:\n",
    "                # Convert all columns except 'id' to a dictionary\n",
    "                comment_info = comment_records.drop(columns=['id']).iloc[0].to_dict()\n",
    "                volunteer_dict['comments'] = comment_info\n",
    "        \n",
    "        nested_volunteers.append(volunteer_dict)\n",
    "\n",
    "# Write the nested data to a JSON file\n",
    "json_file_path = 'volunteers_nested.json'\n",
    "with open(json_file_path, 'w') as f:\n",
    "    json.dump(nested_volunteers, f, indent=4, default=custom_json_serializer)\n",
    "\n",
    "print(f\"Created nested JSON file: {json_file_path} with {len(nested_volunteers)} volunteers\")\n",
    "\n",
    "# Display a sample of the nested data if available\n",
    "if nested_volunteers:\n",
    "    print(\"\\nSample of first volunteer in nested JSON:\")\n",
    "    print(json.dumps(nested_volunteers[0], indent=4, default=custom_json_serializer))\n",
    "else:\n",
    "    print(\"No volunteers to include in nested JSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
